import pandas as pd
import glob
import os
import numpy as np
from datetime import datetime
import pytz
import logging
import math

# --- V5.1 ç­–ç•¥æ‰€éœ€é…ç½®å‚æ•° ---
FUND_DATA_DIR = 'fund_data'
MIN_MONTH_DRAWDOWN = 0.06           # V5.0 éœ‡è¡å¸‚æ ¸å¿ƒè§¦å‘ (å›æ’¤ >= 6%)
HIGH_ELASTICITY_MIN_DRAWDOWN = 0.15 # é«˜å¼¹æ€§ç­–ç•¥çš„åŸºç¡€å›æ’¤è¦æ±‚ (15%)
MIN_DAILY_DROP_PERCENT = 0.03       # å½“æ—¥å¤§è·Œçš„å®šä¹‰ (3%)
REPORT_BASE_NAME = 'fund_warning_report_v5_1_volume'

# --- æ ¸å¿ƒé˜ˆå€¼è°ƒæ•´ ---
EXTREME_RSI_THRESHOLD_P1 = 29.0     # ç½‘æ ¼çº§ï¼šRSI(14) æå€¼è¶…å–
STRONG_RSI_THRESHOLD_P2 = 35.0      # å¼ºåŠ›è¶…å–è§‚å¯Ÿæ± 
SHORT_TERM_RSI_EXTREME = 20.0       # RSI(6)çš„æå€¼è¶…å–é˜ˆå€¼
TREND_HEALTH_THRESHOLD = 0.9        # MA50/MA250 å¥åº·åº¦é˜ˆå€¼
MIN_BUY_SIGNAL_SCORE = 3.7          # æœ€ä½ä¿¡å·åˆ†æ•°
TREND_SLOPE_THRESHOLD = 0.005       # è¶‹åŠ¿æ‹Ÿåˆæ–œç‡é˜ˆå€¼

# --- æ–°å¢ï¼šæˆäº¤é‡ä¸æ´»è·ƒåº¦é˜ˆå€¼ ---
MIN_TURNOVER_RATE = 0.005           # æ¢æ‰‹ç‡é—¨æ§› (0.5%)ï¼Œä½äºæ­¤å€¼è§†ä¸ºæ´»è·ƒåº¦ä¸è¶³
VOLUME_STRETCH_RATIO = 1.5          # æ”¾é‡å®šä¹‰ (å½“æ—¥æˆäº¤é‡ > 5æ—¥å‡é‡ * 1.5)

# --- è®¾ç½®æ—¥å¿— ---
def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('fund_analysis.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

# --- æ•°æ®é¢„å¤„ç† (æ›´æ–°ï¼šæ”¯æŒæˆäº¤é‡å’Œæ¢æ‰‹ç‡) ---
def load_and_preprocess_data(filepath, fund_code):
    try:
        try:
            df = pd.read_csv(filepath)
        except UnicodeDecodeError:
            df = pd.read_csv(filepath, encoding='gbk')
        
        # ç»Ÿä¸€æ˜ å°„è¡¨å¤´ (è¯·ç¡®ä¿æ‚¨çš„ CSV åŒ…å«ä»¥ä¸‹å­—æ®µæˆ–å…¶å˜ä½“)
        column_map = {
            'Date': 'date', 'æ—¥æœŸ': 'date',
            'NetValue': 'net_value', 'å‡€å€¼': 'net_value', 'Close': 'net_value',
            'Volume': 'volume', 'æˆäº¤é‡': 'volume',
            'Turnover': 'turnover_rate', 'æ¢æ‰‹ç‡': 'turnover_rate'
        }
        df = df.rename(columns=column_map)
        
        if 'date' not in df.columns or 'net_value' not in df.columns:
            return None, "ç¼ºå°‘å…³é”®åˆ— (date/net_value)"
            
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values(by='date', ascending=True).reset_index(drop=True)
        df = df.rename(columns={'net_value': 'value'})
        
        # ç¼ºå¤±å€¼å¡«å…… (æˆäº¤é‡è‹¥ç¼ºå¤±å¡«0)
        if 'volume' not in df.columns: df['volume'] = 0
        if 'turnover_rate' not in df.columns: df['turnover_rate'] = 0
        
        if df.empty or len(df) < 60: return None, "æ•°æ®é‡ä¸è¶³"
        
        return df, "æ•°æ®æœ‰æ•ˆ"
    except Exception as e:
        return None, f"åŠ è½½é”™è¯¯: {e}"

# --- å¸ƒæ—å¸¦è®¡ç®— ---
def calculate_bollinger_bands(series, window=20):
    df_temp = pd.DataFrame({'value': series.values})
    df_temp['MA20'] = df_temp['value'].rolling(window=window).mean()
    df_temp['STD20'] = df_temp['value'].rolling(window=window).std()
    
    if df_temp['STD20'].iloc[-1] == 0: return "æ³¢åŠ¨æå°"
        
    df_temp['Lower'] = df_temp['MA20'] - (df_temp['STD20'] * 2)
    df_temp['Upper'] = df_temp['MA20'] + (df_temp['STD20'] * 2)
    
    val = df_temp['value'].iloc[-1]
    low, up = df_temp['Lower'].iloc[-1], df_temp['Upper'].iloc[-1]
    
    if val <= low: return "**ä¸‹è½¨ä¸‹æ–¹**" 
    elif val >= up: return "**ä¸Šè½¨ä¸Šæ–¹**" 
    return "è½¨é“ä¸­é—´"

# --- æŠ€æœ¯æŒ‡æ ‡è®¡ç®— (æ›´æ–°ï¼šåŒ…å«æˆäº¤é‡åˆ†æ) ---
def calculate_technical_indicators(df):
    try:
        df_asc = df.copy()
        # RSI é€»è¾‘
        delta = df_asc['value'].diff()
        for window in [14, 6]:
            gain = delta.where(delta > 0, 0)
            loss = -delta.where(delta < 0, 0)
            avg_gain = gain.ewm(span=window, adjust=False).mean()
            avg_loss = loss.ewm(span=window, adjust=False).mean()
            rs = avg_gain / avg_loss.replace(0, 1e-10)
            df_asc[f'RSI_{window}'] = 100 - (100 / (1 + rs))

        # MACD
        ema12 = df_asc['value'].ewm(span=12, adjust=False).mean()
        ema26 = df_asc['value'].ewm(span=26, adjust=False).mean()
        df_asc['MACD'] = ema12 - ema26
        df_asc['Signal'] = df_asc['MACD'].ewm(span=9, adjust=False).mean()
        
        # æˆäº¤é‡åˆ†æ
        df_asc['Vol_MA5'] = df_asc['volume'].rolling(window=5).mean()
        latest_vol = df_asc['volume'].iloc[-1]
        avg_vol_5 = df_asc['Vol_MA5'].iloc[-1]
        
        volume_status = "å¹³ç¨³"
        if avg_vol_5 > 0:
            if latest_vol > avg_vol_5 * VOLUME_STRETCH_RATIO: volume_status = "æ”¾é‡"
            elif latest_vol < avg_vol_5 * 0.6: volume_status = "ç¼©é‡"

        # è¶‹åŠ¿
        df_asc['MA50'] = df_asc['value'].rolling(window=50).mean()
        df_asc['MA250'] = df_asc['value'].rolling(window=250).mean()
        
        ma50_l = df_asc['MA50'].iloc[-1]
        ma250_l = df_asc['MA250'].iloc[-1]
        ma_ratio = ma50_l / ma250_l if ma250_l else np.nan
        
        return {
            'RSI(14)': round(df_asc['RSI_14'].iloc[-1], 2),
            'RSI(6)': round(df_asc['RSI_6'].iloc[-1], 2),
            'MACDä¿¡å·': 'é‡‘å‰' if df_asc['MACD'].iloc[-1] > df_asc['Signal'].iloc[-1] else 'æ­»å‰',
            'MA50/MA250': round(ma_ratio, 3),
            'å¸ƒæ—å¸¦ä½ç½®': calculate_bollinger_bands(df_asc['value']),
            'æœ€æ–°å‡€å€¼': round(df_asc['value'].iloc[-1], 4),
            'å½“æ—¥è·Œå¹…': round((df_asc['value'].iloc[-1] / df_asc['value'].iloc[-2] - 1), 4) if len(df_asc)>1 else 0,
            'æ¢æ‰‹ç‡': df_asc['turnover_rate'].iloc[-1],
            'é‡æ¯”çŠ¶æ€': volume_status
        }
    except Exception as e:
        logging.error(f"æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        return None

# --- è¡ŒåŠ¨ä¿¡å· (æ›´æ–°ï¼šåŠ å…¥æˆäº¤é‡æƒé‡) ---
def generate_v5_action_signal(row):
    signals = []
    rsi14 = row.get('RSI(14)', 50)
    vol_status = row.get('é‡æ¯”çŠ¶æ€', 'å¹³ç¨³')
    drop = row.get('å½“æ—¥è·Œå¹…', 0)
    
    # æå€¼ä¿¡å· + æ”¾é‡ = ææ…Œç›˜å‡ºå°½
    if rsi14 <= EXTREME_RSI_THRESHOLD_P1:
        prefix = "ğŸ’¥ã€ç½‘æ ¼çº§ã€‘"
        if vol_status == "æ”¾é‡" and drop < -0.02:
            signals.append(f"{prefix}æ”¾é‡ææ…Œå‡ºå°½")
        else:
            signals.append(f"{prefix}RSIæå€¼")

    # æ¢æ‰‹ç‡è¿‡æ»¤é€»è¾‘å¯åœ¨ generate_report å¤„ç†ï¼Œæ­¤å¤„ä»…ç”Ÿæˆæè¿°
    if row.get('æ¢æ‰‹ç‡', 0) < MIN_TURNOVER_RATE and row.get('æ¢æ‰‹ç‡', 0) > 0:
        signals.append("âš ï¸æ´»è·ƒåº¦æä½")

    if not signals: return 'ç­‰å¾…ä¿¡å·'
    return ' | '.join(signals)

# --- æŠ¥å‘Šç”Ÿæˆæ ¸å¿ƒ ---
def generate_report(results, timestamp_str):
    if not results: return "æ— æœ‰æ•ˆæ•°æ®"
    
    df = pd.DataFrame(results)
    # 1. åŸºç¡€ç­›é€‰
    df_filtered = df[df['æœ€å¤§å›æ’¤'] >= MIN_MONTH_DRAWDOWN].copy()
    
    # 2. è¯„åˆ†é€»è¾‘ (é‡èƒ½åŠ åˆ†)
    def score_logic(r):
        score = 0
        if "ç½‘æ ¼çº§" in r['è¡ŒåŠ¨æç¤º']: score += 4.0
        if r['é‡æ¯”çŠ¶æ€'] == "æ”¾é‡" and r['å½“æ—¥è·Œå¹…'] < 0: score += 0.5 # æ”¾é‡ä¸‹è·Œå¾€å¾€æ˜¯åº•éƒ¨
        if r['æ¢æ‰‹ç‡'] < MIN_TURNOVER_RATE: score -= 2.0 # æµåŠ¨æ€§æƒ©ç½š
        return score

    df_filtered['signal_score'] = df_filtered.apply(score_logic, axis=1)
    
    # 3. åˆ†ç»„
    # I.1 å¿…é¡»ï¼šè¶‹åŠ¿å¥åº·ã€åˆ†æ•°è¾¾æ ‡ã€æ¢æ‰‹ç‡åˆæ ¼
    mask_i1 = (df_filtered['MA50/MA250'] >= TREND_HEALTH_THRESHOLD) & \
              (df_filtered['signal_score'] >= 3.0) & \
              (df_filtered['æ¢æ‰‹ç‡'] >= MIN_TURNOVER_RATE)
              
    df_i1 = df_filtered[mask_i1].sort_values(by='signal_score', ascending=False)
    df_others = df_filtered[~mask_i1].sort_values(by='æœ€å¤§å›æ’¤', ascending=False)

    # 4. æ„å»º Markdown (è¡¨æ ¼åˆ—å¢åŠ æˆäº¤é‡/æ¢æ‰‹ç‡)
    report = [f"# åŸºé‡‘ V5.1 é‡ä»·é€‰è‚¡æŠ¥å‘Š ({timestamp_str})\n\n", "## ğŸ¥‡ I.1 æœ€é«˜ä¼˜å…ˆçº§è¯•ä»“ (é‡ä»·é…åˆ)\n\n"]
    
    header = "| åŸºé‡‘ä»£ç  | æœ€å¤§å›æ’¤ | è·Œå¹… | RSI14 | é‡æ¯” | æ¢æ‰‹ | è¡ŒåŠ¨æç¤º | è¶‹åŠ¿ |\n"
    sep = "| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n"
    
    report.append(header + sep)
    for _, row in df_i1.iterrows():
        report.append(f"| `{row['åŸºé‡‘ä»£ç ']}` | {row['æœ€å¤§å›æ’¤']:.2%} | {row['å½“æ—¥è·Œå¹…']:.2%} | {row['RSI(14)']} | {row['é‡æ¯”çŠ¶æ€']} | {row['æ¢æ‰‹ç‡']:.2%} | **{row['è¡ŒåŠ¨æç¤º']}** | {row['MA50/MA250']} |\n")
    
    report.append("\n## âš ï¸ å…¶ä»–è§‚å¯Ÿæ ‡çš„ (æ´»è·ƒåº¦ä¸è¶³æˆ–è¶‹åŠ¿èµ°å¼±)\n\n" + header + sep)
    for _, row in df_others.iterrows():
        report.append(f"| `{row['åŸºé‡‘ä»£ç ']}` | {row['æœ€å¤§å›æ’¤']:.2%} | {row['å½“æ—¥è·Œå¹…']:.2%} | {row['RSI(14)']} | {row['é‡æ¯”çŠ¶æ€']} | {row['æ¢æ‰‹ç‡']:.2%} | {row['è¡ŒåŠ¨æç¤º']} | {row['MA50/MA250']} |\n")

    return "".join(report)

# --- ä¸»å¾ªç¯é€»è¾‘ ---
def analyze_single_fund(filepath):
    fund_code = os.path.splitext(os.path.basename(filepath))[0]
    df, msg = load_and_preprocess_data(filepath, fund_code)
    if df is None: return None
    
    # è®¡ç®—è¿‘ä¸€æœˆå›æ’¤
    mdd = (df['value'].cummax() - df['value']) / df['value'].cummax()
    latest_mdd = mdd.tail(20).max()
    
    tech = calculate_technical_indicators(df)
    if not tech: return None
    
    action = generate_v5_action_signal(tech)
    
    return {
        'åŸºé‡‘ä»£ç ': fund_code,
        'æœ€å¤§å›æ’¤': latest_mdd,
        **tech,
        'è¡ŒåŠ¨æç¤º': action
    }

def main():
    setup_logging()
    if not os.path.exists(FUND_DATA_DIR):
        os.makedirs(FUND_DATA_DIR)
        print(f"è¯·åœ¨ {FUND_DATA_DIR} æ–‡ä»¶å¤¹ä¸­æ”¾å…¥æ•°æ®æ–‡ä»¶ã€‚")
        return

    files = glob.glob(os.path.join(FUND_DATA_DIR, "*.csv"))
    results = [analyze_single_fund(f) for f in files if analyze_single_fund(f)]
    
    report = generate_report(results, datetime.now().strftime('%Y-%m-%d %H:%M'))
    
    save_path = f"Report_V5_1_{datetime.now().strftime('%Y%m%d')}.md"
    with open(save_path, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"åˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ç”Ÿæˆï¼š{save_path}")

if __name__ == "__main__":
    main()