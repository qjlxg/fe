import pandas as pd
import glob
import os
import numpy as np
from datetime import datetime, timedelta
import warnings

warnings.filterwarnings('ignore')

# --- æ ¸å¿ƒå‚æ•° ---
TOTAL_CAPITAL = 100000       
DATA_DIR = 'fund_data'
PORTFOLIO_FILE = 'portfolio.csv'
TRACKER_FILE = 'signal_performance_tracker.csv'
REPORT_FILE = 'README.md'
MARKET_INDEX = '510300'
MIN_SCORE_SHOW = 3

# --- 1. å¢å¼ºç‰ˆè¡Œä¸šä¸åç§°è¯†åˆ«å¼•æ“ ---
def get_beijing_time():
    return datetime.utcnow() + timedelta(hours=8)

def get_fund_info_map():
    """å¤šçº§æŠ“å–ï¼šå…ˆå°è¯•APIï¼Œå¤±è´¥åˆ™ç”¨æœ¬åœ°å…œåº•"""
    name_map = {
        # æœ¬åœ°æ ¸å¿ƒåº“å…œåº•ï¼ˆè¦†ç›–å¸‚é¢ 80% æˆäº¤é¢æ ‡çš„ï¼‰
        "159102": "ä¸­è¯1000ETF", "513060": "æ’ç”ŸåŒ»ç–—ETF", "512170": "åŒ»ç–—ETF",
        "513050": "ä¸­æ¦‚äº’è”ç½‘ETF", "510300": "æ²ªæ·±300ETF", "159915": "åˆ›ä¸šæ¿ETF",
        "513100": "çº³æŒ‡ETF", "510500": "ä¸­è¯500ETF", "588000": "ç§‘åˆ›50ETF",
        "159659": "æ’ç”Ÿç§‘æŠ€ETF", "513330": "æ’ç”Ÿç§‘æŠ€ETF", "513130": "æ’ç”Ÿç§‘æŠ€ETF"
    }
    try:
        import akshare as ak
        # å°è¯•ä»æ–°æµªæ¥å£è·å–å®æ—¶åˆ—è¡¨
        df = ak.fund_etf_category_sina("ETFåŸºé‡‘")
        api_map = dict(zip(df['ä»£ç '].str[-6:], df['åç§°'])) # ç¡®ä¿åªåŒ¹é…å6ä½æ•°å­—
        name_map.update(api_map)
    except Exception as e:
        print(f"âš ï¸ APIæŠ“å–å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°å…œåº•åº“: {e}")
    return name_map

def get_fund_tag(name):
    """å…³é”®è¯è¯­ä¹‰æ‰“æ ‡ç­¾"""
    tags = {
        "åŒ»ç–—/åŒ»è¯": ["åŒ»", "è¯", "ç”Ÿç‰©"],
        "äº’è”ç½‘/ç§‘æŠ€": ["ç½‘", "äº’è”", "ç§‘æŠ€", "èŠ¯ç‰‡", "åŠå¯¼ä½“"],
        "æ–°èƒ½æº/ç”µåŠ›": ["ç¢³", "èƒ½", "å…‰ä¼", "ç”µ"],
        "å®½åŸº/æŒ‡æ•°": ["1000", "500", "300", "50", "åˆ›ä¸šæ¿", "ç§‘åˆ›", "æ’ç”Ÿ"],
        "æ¶ˆè´¹/ç™½é…’": ["é…’", "æ¶ˆ", "é£Ÿ"]
    }
    for tag, keys in tags.items():
        if any(k in name for k in keys): return tag
    return "è¡Œä¸šä¸»é¢˜"

# --- 2. ç­–ç•¥é€»è¾‘æ¨¡å— ---
def analyze_signal(df):
    if len(df) < 30: return None
    # è‡ªåŠ¨è¯†åˆ«åˆ—å
    mapping = {'æ—¥æœŸ': 'date', 'æ”¶ç›˜': 'close', 'æˆäº¤é¢': 'amount', 'æœ€é«˜': 'high', 'æœ€ä½': 'low'}
    df.rename(columns=mapping, inplace=True)
    df.columns = [c.lower() for c in df.columns]
    
    last = df.iloc[-1]
    ma5 = df['close'].rolling(5).mean().iloc[-1]
    ma10 = df['close'].rolling(10).mean().iloc[-1]
    amt_ma5 = df['amount'].rolling(5).mean().iloc[-1]
    peak_20 = df['close'].rolling(20).max().iloc[-1]
    dd = (last['close'] - peak_20) / peak_20
    roc20 = (last['close'] / df['close'].shift(20).iloc[-1]) - 1

    score = 0
    if last['close'] > ma5 and dd < -0.06:
        score = 1
        if last['close'] > ma10: score += 1
        if last['amount'] > amt_ma5: score += 1
            
    if score >= 1:
        # é£é™©ç®¡ç†ï¼šå•ç¬”äºæŸæ§åˆ¶åœ¨æ€»æœ¬é‡‘ 2%
        risk_per_trade = TOTAL_CAPITAL * 0.02
        stop_gap = max(last['close'] - (ma10 * 0.97), 0.01)
        shares = int(risk_per_trade / stop_gap // 100 * 100)
        return {
            'roc': roc20 * 100, 'score': score, 'price': last['close'],
            'stop': ma10 * 0.97, 'shares': shares,
            'date': get_beijing_time().strftime('%Y-%m-%d')
        }
    return None

# --- 3. æ‰§è¡Œå¼•æ“ ---
def execute():
    bj_now = get_beijing_time()
    name_map = get_fund_info_map()
    files = glob.glob(os.path.join(DATA_DIR, "*.csv"))
    all_signals = []

    # å¤§ç›˜åŸºå‡†åˆ†æ
    mkt_bias = 0
    mkt_path = os.path.join(DATA_DIR, f"{MARKET_INDEX}.csv")
    if os.path.exists(mkt_path):
        m_df = pd.read_csv(mkt_path)
        m_df.rename(columns={'æ”¶ç›˜':'close'}, inplace=True)
        m_ma20 = m_df['close'].rolling(20).mean().iloc[-1]
        mkt_bias = (m_df['close'].iloc[-1] / m_ma20 - 1)

    for f in files:
        code = os.path.splitext(os.path.basename(f))[0]
        if code == MARKET_INDEX: continue
        try:
            res = analyze_signal(pd.read_csv(f))
            if res:
                res['code'] = code
                res['name'] = name_map.get(code, "æœªçŸ¥æ ‡çš„")
                # å¦‚æœä¾ç„¶æœªçŸ¥ï¼Œå°è¯•å¤„ç†å¸¦å‰ç¼€çš„ä»£ç 
                if res['name'] == "æœªçŸ¥æ ‡çš„":
                    res['name'] = name_map.get(f"sh{code}", name_map.get(f"sz{code}", "æœªçŸ¥æ ‡çš„"))
                res['tag'] = get_fund_tag(res['name'])
                all_signals.append(res)
        except: continue

    elite = [s for s in all_signals if s['score'] >= MIN_SCORE_SHOW]
    elite.sort(key=lambda x: x['roc'], reverse=True)

    # æ¸²æŸ“ README
    with open(REPORT_FILE, "w", encoding="utf_8_sig") as f:
        f.write(f"# ğŸ›°ï¸ å¤©æ¢ ETF ç²¾è‹±çœ‹æ¿\n\n")
        f.write(f"æœ€ååŒæ­¥ (åŒ—äº¬æ—¶é—´): `{bj_now.strftime('%Y-%m-%d %H:%M')}`\n\n")
        f.write(f"### ğŸ“Š å¸‚åœºåº•è‰²\n- å¤§ç›˜åç¦»åº¦ (Bias20): `{mkt_bias:.2%}`\n")
        f.write(f"- é£æ§å»ºè®®: {'ğŸŸ¢ ç§¯ææ¢è·¯' if mkt_bias > -0.01 else 'ğŸŸ¡ ä¸¥æ ¼æ­¢æŸ'}\n\n")
        
        f.write(f"### ğŸ¯ ç²¾è‹±å…¥åœºä¿¡å· (å¾—åˆ† â‰¥ {MIN_SCORE_SHOW})\n")
        if elite:
            f.write("| ä»£ç  | åŸºé‡‘ç®€ç§° | è¡Œä¸š/ä¸»é¢˜ | ROC20% | å¾—åˆ† | ç°ä»· | å»ºè®®ä¹°å…¥ | æ­¢æŸå‚è€ƒ |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n")
            for s in elite:
                score_str = "ğŸ”¥" * s['score']
                f.write(f"| {s['code']} | **{s['name']}** | `{s['tag']}` | {s['roc']:.2f}% | {score_str} | {s['price']:.3f} | {s['shares']}è‚¡ | {s['stop']:.3f} |\n")
        else:
            f.write("> ğŸ˜´ ä»Šæ—¥æš‚æ— ç²¾è‹±å…±æŒ¯ä¿¡å·ã€‚")

    if all_signals:
        pd.DataFrame(all_signals).to_csv(TRACKER_FILE, index=False, mode='a', header=not os.path.exists(TRACKER_FILE), encoding='utf_8_sig')

if __name__ == "__main__":
    execute()
